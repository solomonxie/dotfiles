#######################################################################
#                               COMMON                                #
#######################################################################
snippet ifmain
def main():
	${1:${VISUAL:pass}}


if __name__ == '__main__':
	main()
endsnippet


snippet jsonload
with open('${1:${VISUAL:path}}', 'r') as f:
	${2:${VISUAL:data}} = json.loads(f.read())
endsnippet

snippet jsondump
with open('${1:${VISUAL:path}}', 'w') as f:
	f.write(json.dumps(${2:${VISUAL:data}}))
endsnippet


snippet parse-url
import urllib
urlobj = urllib.parse.urlparse(url)
endsnippet

snippet parse-url-params
import urllib
urlobj = urllib.parse.urlparse(url)
params = urllib.parse.parse_qs(urlobj.query)
endsnippet


snippet	shuffle_list
shuffled_list = sorted(${1:${VISUAL:target_list}}, key=lambda _: random.random())
endsnippet

#######################################################################
#                              DEBUGGING                              #
#######################################################################
snippet pdb
__import__('pdb').set_trace()
endsnippet

snippet ipdb
__import__('ipdb').set_trace()
endsnippet

snippet pp
__import__('pprint').pprint(${1})
endsnippet

snippet pprint
__import__('pprint').pprint(${1})
endsnippet

snippet sleep
__import__('time').sleep(${1})
endsnippet

snippet snoop
with __import__('pysnooper').snoop():
	${0:put_code_under_here_for_snooping}
endsnippet


snippet logger
from logging import getLogger
logger = getLogger(__name__)
endsnippet


#######################################################################
#                              FILE I/O                               #
#######################################################################
snippet csv_reader
reader
endsnippet

snippet csv_writer
cols = ['col1', 'col2']
buff = __import__('io').StringIO()
writer = __import__('csv').DictWriter(buff, fieldnames=cols)
writer.writeheader()
writer.writerow({'name': ['psycho1', 'psycho2'], 'age': [10, 20]})
writer.writerows([{'name': 'jason', 'age': 18}, {'name': 'tom', 'age': 20}])
print(buff.getvalue())
endsnippet

snippet string_io
buff = __import__('io').StringIO()
buff.write('hello')
print(buffer.getvalue())
endsnippet

snippet buffer_io
buff = __import__('io').BytesIO()
buff.write(b'hello')
print(buffer.getvalue())
endsnippet

snippet file_io
endsnippet

snippet gzip_compress
content = __import__('gzip').compress(b'${1:${VISUAL:hello}}', compresslevel=9)
endsnippet


#######################################################################
#                           TEST FRAMEWORK                            #
#######################################################################
snippet mock_constant
patch('${1:module.module.constant_name}', '${2:mocked_value}').start()
endsnippet

snippet mock_method
patch('${1:module.module.method}', MagicMock(return_value=${2:mocked_value})).start()
endsnippet

snippet mock_property
patch(${1:module.module.class_name}, '${2:property_name}', ${3:expected_value}).start()
endsnippet

snippet mock_exception
patch('${1:module.module.method_name}', MagicMock(side_effect=Exception('${2:err_msg}'))).start()
endsnippet


snippet testcase
from unittest import TestCase


class Test${1:${VISUAL:Name}}(TestCase):
	def setUp(self):
		pass

	def tearDown(self):
		pass

	def test_${2:${VISUAL:case_name}}(self):
		self.assertEqual(1, 1)
endsnippet


snippet patch
from unittest.mock import patch, MagicMock
@patch('${1:${VISUAL:module_path}}',
		MagicMock(return_value=${2:${VISUAL:mock_data}}))
endsnippet

#######################################################################
#                     SQLAlchemy - DB OPERATIONS                      #
#######################################################################



#######################################################################
#                         Pandas - DATAFRAME                          #
#######################################################################



#######################################################################
#                              AWS - S3                               #
#######################################################################

snippet s3_client
import boto3
def get_s3_client():
	return boto3.client(
		's3',
		aws_access_key_id='${1:{VISUAL:key_id}}',
		aws_secret_access_key='${2:{VISUAL:secret}}',
		# config=boto3.session.Config(signature_version='s3v4'),
		# endpoint_url='http://your-own-endpoint',
		# region_name='your-region',
	)
endsnippet

snippet s3_resource
import boto3
def get_s3_resource():
	return boto3.resource(
		's3',
		aws_access_key_id='${1:{VISUAL:key_id}}',
		aws_secret_access_key='${2:{VISUAL:secret}}',
		# config=boto3.session.Config(signature_version='s3v4'),
		# endpoint_url='http://your-own-endpoint',
		# region_name='your-region',
	)
endsnippet


snippet s3_create_bucket_if_not_exist
def create_bucket_if_not_exists(bucket):
	s3 = get_s3_resource()
	if not s3.Bucket(bucket).creation_date:
		info = s3.create_bucket(Bucket=bucket)
		print('Created bucket:', info)
	return s3.Bucket(bucket).creation_date
endsnippet



snippet s3_delete_bucket
def delete_bucket(bucket_name):
	s3 = get_s3_resource()
	bucket = s3.Bucket(bucket_name)
	if bucket.creation_date:
		_ = [key.delete() for key in bucket.objects.all()]
		bucket.delete()
endsnippet


snippet s3_upload_resource
def upload_resource(path, bucket, object_name=None):
	if not os.path.exists(path):
		return None
	s3 = get_s3_resource()
	object_name = object_name or os.path.basename(path)
	s3.Bucket(bucket).upload_file(path, object_name)
endsnippet


snippet s3_upload
def upload(filepath, bucket, object_name=None):
	if not os.path.exists(path):
		return None
	object_name = object_name or os.path.basename(path)
	s3 = get_s3_client()
	s3.upload_file(filepath, bucket, object_name)
endsnippet


snippet s3_get_signed_url
def get_signed_url(bucket, object_name):
	s3 = get_s3_client()
	url = s3.generate_presigned_url(
		ClientMethod='get_object',
		Params={
			'Bucket': bucket,
			'Key': object_name,
		},
		ExpiresIn=None,
		HttpMethod=None,
	)
	return url
endsnippet


snippet s3_upload_from_buffer
def upload_from_buffer(client, bucket, path):
	buff = __import__('io').StringIO()
	buff.write('haha')
	resp = client.put_object(Body=buff.getvalue(), Bucket=bucket, Key=path)

endsnippet



#######################################################################
#                        Numpy - DATA SCIENCE                         #
#######################################################################

snippet random_matrix

endsnippet


#######################################################################
#                              UTILITIES                              #
#######################################################################
snippet url_change_port
import urllib
obj = urllib.parse.urlparse(url)
url = obj._replace(netloc=f'{obj.hostname}:${1:expected_port}').geturl()
endsnippet


snippet chunks
def chunks(l, size):
	for i in range(0, len(l), size):
		yield l[i:i+size]
endsnippet

snippet ichunks
def ichunks(generator, size):
	"""
	GOOD TO SPLIT A GENERATOR TO CHUNKS WITHOUT WALK THROUGH EVERY ITEM
	"""
	iterable_generator = iter(generator)
	while True:
		items = list(islice(iterable_generator, size))
		if not items:
		break
		yield items
endsnippet

snippet islice
def islice(maximum, chunk_size):
	for i in range(0, maximum - maximum % chunk_size + chunk_size, chunk_size):
		yield slice(i, min(i + chunk_size, maximum))
endsnippet

snippet meminfo
import psutil
def mem_info():
	used = format(psutil.virtual_memory().used / 1024 / 1024 / 1024, '.2f')
	total = format(psutil.virtual_memory().total / 1024 / 1024 / 1024, '.2f')
	percent = psutil.virtual_memory().percent
	logger.info('*'*15 + f'Current memory usage ({percent}%): [{used}GB / {total}GB]' + '*'*15)
	return percent
endsnippet

snippet oscheck
import psutil
def os_check(wait=2, timeout=60*60, mem_use=10, cpu_use=70, disk_free=5):
	"""
	:mem: Memory Usage (GB)
	:cpu: CPU Usage percentage
	:disk: Disk free size (GB)
	"""
	begin = time()
	mem, cpu, disk = get_os_usage()
	# mem_rank, cpu_rank = get_top_os_usage_processes()

	# while mem > mem_use or cpu > cpu_use or disk < disk_free:
	while mem > mem_use:
		if time() - begin > timeout:
			logger.critical('_'*15 + 'Memory usage is high for too long. Now quit waiting' + '_'*15)
			break  # Quit looping if it's waiting too long
		if mem > mem_use:
			gc.collect()
		if cpu > cpu_use:
			logger.info('#'*10 + f'CPU USAGE: {cpu}%.' + '#'*10)
		if disk < disk_free:
			logger.info('$'*10 + f'DISK FREE: {disk}GB' + '$'*10)
		sleep(wait)
		mem, cpu, disk = get_os_usage()  # Refresh current info
endsnippet

snippet osusage
import psutil
def get_os_usage():
	mem = psutil.virtual_memory().used / 1024 / 1024 / 1024  # GB
	cpu = mean(psutil.cpu_percent(interval=0.01, percpu=True))
	disk = psutil.disk_usage('/').free / 1024 / 1024 / 1024  # GB
	return mem, cpu, disk
endsnippet

snippet osusagetopprocesses
def get_top_os_usage_processes(top=1):
	top_mem_use, top_cpu_use = [], []
	# Iterate over all running process
	for proc in psutil.process_iter():
		try:
			pname = proc.name()
			mem_use = round(proc.memory_info().vms / 1024 / 1024, 2)  # MB
			# cpu_use = round(proc.cpu_percent() / psutil.cpu_count(), 2)
			cpu_use = max([proc.cpu_percent(interval=0.001) for i in range(1, 5)])
			top_mem_use.append(', '.join((pname, f'{mem_use} MB')))
			top_cpu_use.append(', '.join((pname, f'{cpu_use}%')))
		except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
			continue
	mem_rank = sorted(top_mem_use, reverse=True, key=lambda x: x[1])
	cpu_rank = sorted(top_cpu_use, reverse=True, key=lambda x: x[1])
	return mem_rank[:top], cpu_rank[:top]
endsnippet

snippet daterange
def get_date_range(granularity, start_date):
	"""
	get start_date and end_date from start_date and granularity
	:param granularity:
	:param start_date:
	:return:
	"""
	if granularity == 'daily':
		# run current day
		return start_date, start_date

	elif granularity == 'weekly':
		# run current week
		# sunday is first day
		target_date_obj = datetime.strptime(start_date, '%Y-%m-%d')
		week_begin_date = target_date_obj - timedelta(days=(target_date_obj.isoweekday() % 7))
		week_end_date = week_begin_date + timedelta(days=6)

		return str(week_begin_date.date()), str(week_end_date.date())

	elif granularity == 'monthly':
		# run current month
		month_begin_date = datetime.strptime(start_date, '%Y-%m-%d').replace(day=1)
		next_month_date = datetime.strptime(start_date, '%Y-%m-%d').replace(day=28) + timedelta(days=4)
		month_end_date = next_month_date - timedelta(days=next_month_date.day)
		return str(month_begin_date.date()), str(month_end_date.date())

	else:
		raise Exception(f'Unknown granularity: {granularity}')
endsnippet
